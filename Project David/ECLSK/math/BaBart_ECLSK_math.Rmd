---
title: "BaBart presentation 5-mei"
author: "David Eleveld s1741225"
date: "3-5-2022"
output: pdf_document
---

#Presentatie 5-mei 2022

Met een kleine verandering heb ik volgens mij eindelijk de correcte posterior distribution weten te vinden. In het bart-element staat namelijk een `...$yhat.train`. Deze heeft de correcte dimensies en de zelfde gemiddeldes als `...$yhat.train.mean`. 

Sidenote: je moet BINNEN de bart functie een seed setten met `seed = ...`. Als je dit niet doet, maar wel een seed set voor de bart functie werkt het niet.

#Setup

##Load requiered packages

```{r Packages, include=FALSE}
library("haven")
library("dbarts")
library("glmertree")
library("dplyr")
library("here")
library("multilevel")
library("tidyverse")
```

##Bayesian data generation function

```{r Bayesian Data generation}
gendata_bay <- function(data, PPD, n_gen){
  
  if(nrow(data) != ncol(PPD)){stop("Amount of observations in PPD is different from data")}
  
  index_gen <- sample.int(n = nrow(data), size = n_gen, replace = TRUE)
  x_gen <- data[index_gen,]
  y_gen <- sapply(index_gen, function(i) sample(x = PPD[,i], size = 1))
  # y_gen <- sapply(index_gen, function(i) sample(x = PPD[,i][PPD[,i] >= quantile(PPD[,i], probs = .40) & PPD[,i] <= quantile(PPD[,i], probs = .60)], size = 1))
  
  return(cbind(x_gen, y_gen))
}
```

##Smearing data generation function

```{r Smearing}
gendata_smr <- function(data, palt = 0.5, n_gen){

  if(palt < 0 | palt > 1){stop("palt must be bound between between 0 and 1")}
  
  index_gen <- sample.int(n = nrow(data), size = n_gen, replace = TRUE)
  gen_data <- data[index_gen,]
  
  if(palt != 0){
    for(i in 1:nrow(gen_data)){
      
      for(j in 1:ncol(gen_data)){
        
        if(runif(1) <= palt){gen_data[i,j] <- sample(x = data[,j], size = 1)}
      }
    }
  }
  return(gen_data)
}
```


##Load Safety data

```{r Load Safety data}
set.seed(42)

load(file.path(here(),"Project David","ECLSK","Math ability data.Rdata"))

data <- mathdata[mathdata$CHILDID %in% sample(x = unique(mathdata$CHILDID), size = 240),]

sapply(X = data, FUN = class)
table(data$RACE)

data$CHILDID <- factor(data$CHILDID)

rm(mathdata)
```

##Single GLMM tree

```{r}
set.seed(42)
nfolds <- 10
nreps <- 10
ngensizes <- c(1,5)
palts <- c(0.25, 0.5)
tel <- 0
use_weights <- TRUE
baygen <- FALSE


if(baygen){
  tree_size <- MSE <- as.data.frame(matrix(data = NA, nrow = nfolds*nreps, ncol = 2 + length(ngensizes)))
  colnames(tree_size) <- colnames(MSE) <- c("GLMM_tree","Bart",paste0("BaBart_N*",ngensizes))
  rownames(tree_size) <- rownames(MSE) <- paste0("rep",sort(rep(1:nreps, times = nfolds)),"_fold",rep(1:nfolds, times = nreps))
}else{
  tree_size <- MSE <- as.data.frame(matrix(data = NA, nrow = nfolds*nreps, ncol = length(ngensizes)*length(palts)))
  colnames(tree_size) <- colnames(MSE) <- c(paste0("Smearing_N*",expand.grid(ngensizes,palts)[,1], "_palt=",expand.grid(ngensizes,palts)[,2]))
  rownames(tree_size) <- rownames(MSE) <- paste0("rep",sort(rep(1:nreps, times = nfolds)),"_fold",rep(1:nfolds, times = nreps))
}


system.time(
for (k in 1:nreps){
  
  # this block makes sure "traindat" contains every level
  levelvec <- 0
  while(mean(levelvec) != 1) {
    fold_ids <- sample(rep(1:nfolds, times = ceiling(nrow(data)/nfolds)), size = nrow(data), replace = FALSE)
    levelvec <- numeric()
      for (i in 1:nfolds){
        
        # same as CHILDID but for RACE
        if(min(table(data[fold_ids != i, ]$RACE)) < 1){
          levelvec <- 0
          print("stout!")
          break} 
        
        trainlevels <- data[fold_ids != i, ]$CHILDID
        testlevels <- data[fold_ids == i, ]$CHILDID
        levelvec[i] <- mean(testlevels %in% trainlevels)
        print(levelvec)
        if(levelvec[i] != 1){break}
      }
  }
  
  for (i in 1:nfolds){
    
    traindat <- data[fold_ids != i, ]
    testdat <- data[fold_ids == i, ]
    
    if(baygen){
      # Fit a regualar GLMM tree
      glmtree <- lmertree(score ~ months | (1|CHILDID) | GENDER + RACE + WKSESL + 
                            C1GMOTOR + C1FMOTOR + T1INTERN + T1EXTERN + 
                            T1INTERP + T1CONTRO + P1FIRKDG + AGEBASELINE,
                       cluster = CHILDID, data = traindat)
  
      pred_glmtree <- predict(glmtree, newdata = testdat, allow.new.levels = TRUE)
  
      MSE[(k-1)*10+i,1] <- mean((testdat$score - pred_glmtree)^2)
      tree_size[(k-1)*10+i,1] <- (length(glmtree$tree)-1)/2
      
      # fit multilevel BART
      Mbart <- rbart_vi(score ~ GENDER + RACE + WKSESL + C1GMOTOR + C1FMOTOR + 
                          T1INTERN + T1EXTERN + T1INTERP + T1CONTRO + P1FIRKDG + 
                          AGEBASELINE + months,
         data = traindat, group.by = traindat$CHILDID,
         test = testdat, group.by.test = testdat$CHILDID,
         n.trees = 100, keepTrees = TRUE, combineChains = TRUE, seed = 42)
      
      posterior <- Mbart$yhat.train
      
      MSE[(k-1)*10+i,2] <- mean((testdat$score - Mbart$yhat.test.mean)^2) 
    }
    
    # fit BaBart GLMM trees with different sizes of Ngen
    for(ngen in ngensizes){
      
      if(baygen){
        surr_mlbart <- gendata_bay(traindat, posterior, ngen * nrow(traindat))
        
        if(use_weights){
          babart <- lmertree(y_gen ~ months | (1|CHILDID) | GENDER + RACE + WKSESL + 
                               C1GMOTOR + C1FMOTOR + T1INTERN + T1EXTERN + 
                               T1INTERP + T1CONTRO + P1FIRKDG + AGEBASELINE,
                           cluster = CHILDID, data = surr_mlbart, 
                           weights = rep(1/ngen, times = nrow(surr_mlbart)))
        }
        else{
            babart <- lmertree(y_gen ~ months | (1|CHILDID) | GENDER + RACE + WKSESL + 
                         C1GMOTOR + C1FMOTOR + T1INTERN + T1EXTERN + 
                         T1INTERP + T1CONTRO + P1FIRKDG + AGEBASELINE,
                     cluster = CHILDID, data = surr_mlbart, maxdepth = 5)
        }
      pred_babart <- predict(babart, newdata = testdat, allow.new.levels = TRUE)
      MSE[(k-1)*10+i,2+match(ngen,ngensizes)] <- mean((testdat$score - pred_babart)^2)
      tree_size[(k-1)*10+i,2+match(ngen,ngensizes)] <- (length(babart$tree)-1)/2
      }
      else{
        for(palt in palts){
          
          surr_mlbart <- gendata_smr(traindat, palt, ngen * nrow(traindat))
          
          Mbart <- rbart_vi(score ~ GENDER + RACE + WKSESL + C1GMOTOR + C1FMOTOR + 
                          T1INTERN + T1EXTERN + T1INTERP + T1CONTRO + P1FIRKDG + 
                          AGEBASELINE + months,
                       data = surr_mlbart, group.by = surr_mlbart$CHILDID,
                       n.trees = 100, keepTrees = TRUE, combineChains = TRUE, seed = 42)
          
          y_gen <- Mbart$yhat.train.mean
          surr_mlbart <- cbind(surr_mlbart, y_gen)
          
          if(use_weights){
            babart <- lmertree(y_gen ~ months | (1|CHILDID) | GENDER + RACE + WKSESL + 
                               C1GMOTOR + C1FMOTOR + T1INTERN + T1EXTERN + 
                               T1INTERP + T1CONTRO + P1FIRKDG + AGEBASELINE,
                           cluster = CHILDID, data = surr_mlbart, 
                           weights = rep(1/ngen, times = nrow(surr_mlbart)))
          }
          else{
            babart <- lmertree(y_gen ~ months | (1|CHILDID) | GENDER + RACE + WKSESL + 
                         C1GMOTOR + C1FMOTOR + T1INTERN + T1EXTERN + 
                         T1INTERP + T1CONTRO + P1FIRKDG + AGEBASELINE,
                     cluster = CHILDID, data = surr_mlbart, maxdepth = 5)
          }
          pred_babart <- predict(babart, newdata = testdat, allow.new.levels = TRUE)
          MSE[(k-1)*10+i,match(ngen,ngensizes)+(match(palt, palts)-1)*length(ngensizes)] <- mean((testdat$score - pred_babart)^2)
          tree_size[(k-1)*10+i,match(ngen,ngensizes)+(match(palt, palts)-1)*length(ngensizes)] <- (length(babart$tree)-1)/2
        }
      }
      
      
      
    }
    
    tel <- tel + 1
    print(paste0("[",round((tel)/(nreps*nfolds)*100),"%]"))
  }
}
)
```

Save/Load data

```{r}
# save MSE as CSV
write.csv(x = MSE, file = paste("MSE","Math",if(baygen){paste0("baygen[",paste(ngensizes, collapse = ","),"]")}else{paste0("smearing[",paste0(palt*100,"%", collapse = ","),"]")}, if(use_weights){"weighted"}, sep = "_"))

# save tree_size as CSV
write.csv(x = tree_size, file = paste("TreeSize","Math",if(baygen){paste0("baygen[",paste(ngensizes, collapse = ","),"]")}else{paste0("smearing[",paste0(palt*100,"%", collapse = ","),"]")}, if(use_weights){"weighted"}, sep = "_"))
```


Visualisation

```{r}
apply(X = MSE, MARGIN = 2, FUN = mean)
apply(X = MSE, MARGIN = 2, FUN = sd)
apply(X = tree_size, MARGIN = 2, FUN = mean)
apply(X = tree_size, MARGIN = 2, FUN = sd)

# MSE_long <- MSE %>% gather(key = "Method", value = "MSE")
# MSE_long$Method <- as.factor(MSE_long$Method)
par(mar = c(7.1, 4.1, 4.1, 2.1))
boxplot(MSE, horizontal = F, las = 2)
abline(h = median(MSE$Bart))

# tree_size_long <- tree_size %>% gather(key = "Method", value = "MSE")
# tree_size_long$Method <- as.factor(tree_size_long$Method)
par(mar = c(7.1, 4.1, 4.1, 2.1))
boxplot(tree_size, horizontal = F, las = 2)
abline(h = median(MSE$Bart))
```

