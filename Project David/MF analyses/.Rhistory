rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,1,.5)
rbinom(1,5,.5)
rbinom(1,5,.5)
rbinom(1,5,.5)
rbinom(1,5,.5)
rbinom(1,5,.5)
rbinom(1,5,.5)
rbinom(10,1,.5)
nfolds <- 10
nreps <- 10
ngensizes <- c(1, 5, 10)
palts <- c(0, 0.25, 0.5, 1.0)
BaSmear_design <- expand.grid(ngensizes, palts)
BaSmear_design
View(BaSmear_design)
for(i in BaSmear_design){}
for(i in BaSmear_design){print(i)}
for(i in BaSmear_design){print(i)}
for(i in BaSmear_design){print(i);print("ieks")}
binomial()
binomial()$linkinv
binomial()$linkinv()
try({})
try({5/0})
try({5/a})
try({})
try({
for(i in c(1,2,"a",4)){
print(5/i)
}
})
## Bayesian data generation function
## Returns X_gen, y_gen
gendata_bay <- function(data, PPD, ngen) {
if (nrow(data) != ncol(PPD))
stop("Amount of observations in PPD is different from data")
index_gen <- sample.int(n = nrow(data), size = ngen*nrow(data), replace = TRUE)
x_gen <- data[index_gen, ]
## Posterior Predictive Distribution has 2000 rows (default) and nobs columns
## Thus, for each bootstrap sampled row, selected correspdonding column
## and sample a random value from that posterior
y_gen <- sapply(index_gen, function(i) sample(x = PPD[ , i], size = 1))
return(cbind(x_gen, y_gen))
}
## Smearing data generation function
## Returns X_gen only
gendata_smr <- function(data, palt = 0.5, ngen) {
if (palt < 0 | palt > 1) stop("palt must be bound between between 0 and 1")
index_gen <- sample.int(n = nrow(data), size = ngen*nrow(data), replace = TRUE)
gen_data <- data[index_gen, ]
## With probability palt, replace value in X_gen with random sample from
## corresponding column
if (palt != 0) {
for (i in 1:nrow(gen_data)) {
for (j in 1:ncol(gen_data)) {
if (rbinom(n = 1, size = 1, prob = palt)) {
gen_data[i, j] <- sample(x = data[ , j], size = 1)
}
}
}
}
return(gen_data)
}
data(BreastCancer)
data <- BreastCancer
library("partykit")
library("partykit")
library("dbarts")
library("mlbench")
data(BreastCancer)
data <- BreastCancer
data <- na.omit(data)
data[ , sapply(data, is.ordered)] <- sapply(data[ , sapply(data, is.ordered)], as.numeric)
nfolds <- 10
nreps <- 10
ngensizes <- c(1, 5, 10)
palts <- c(0, 0.25, 0.5)
## Create objects for saving results (MSE for Bayesian approach, MSE2 for Breiman approach)
MSE <- data.frame(matrix(data = NA, nrow = nfolds*nreps,
ncol = 3 + length(ngensizes) + length(ngensizes)*length(palts)))
BaSmear_design <- expand.grid(ngensizes, palts)
colnames(BaSmear_design) <- c("ngen", "palt")
colnames(MSE) <- c("tree", "BART", "Born-again tree",
paste0("N=", ngensizes),
paste0("N=", BaSmear_design[ , 1], ", palt=", BaSmear_design[ , 2]))
rownames(MSE) <- paste0("rep", sort(rep(1:nreps, times = nfolds)), "_fold", rep(1:nfolds, times = nreps))
#MSE <- MSE[ , -which(is.na(colnames(MSE)))]
tree_size <- acc <- MSE
## Generate train-test splits
fold_ids <- sample(rep(1:nfolds, times = ceiling(nrow(data)/nfolds)),
size = nrow(data), replace = FALSE)
## Select train and test data
traindat <- data[fold_ids != i, -which(names(data) == "Id")]
testdat <- data[fold_ids == i, ]
## Check whether all factor levels in test are also in train, else move obs.
for (fact in c("Bare.nuclei", "Bl.cromatin", "Normal.nucleoli", "Mitoses")) {
levs <- unique(testdat[ , fact]) %in% unique(traindat[ , fact])
if (!all(levs)) {
test <- test[-which(!testdat[ , fact] %in% unique(testdat[ , fact])[levs]), ]
print(paste0("Levels of ", i, " omitted from test data: ",
unique(testdat[ , fact])[!levs]))
}
}
train_x <- traindat[ , -which(names(traindat) == "Class")]
train_y <- as.numeric(traindat$Class) - 1
test_x <- testdat[ , -which(names(data) == "Class")]
test_y <- as.numeric(testdat$Class) - 1
View(train_x)
## Fit regular GLMM tree
gt <- glmtree(Class ~ 1 | ., data = traindat, family = binomial)
## Fit regular GLMM tree
gt <- glmtree(Class ~ 1 | ., data = traindat, family = binomial)
pred_gt <- predict(gt, newdata = testdat, type = "response")
MSE[(k-1)*10+i, 1] <- mean((test_y - pred_gt)^2)
k = 1
## Fit regular GLMM tree
gt <- glmtree(Class ~ 1 | ., data = traindat, family = binomial)
pred_gt <- predict(gt, newdata = testdat, type = "response")
MSE[(k-1)*10+i, 1] <- mean((test_y - pred_gt)^2)
i = 1
## Select train and test data
traindat <- data[fold_ids != i, -which(names(data) == "Id")]
testdat <- data[fold_ids == i, ]
## Check whether all factor levels in test are also in train, else move obs.
for (fact in c("Bare.nuclei", "Bl.cromatin", "Normal.nucleoli", "Mitoses")) {
levs <- unique(testdat[ , fact]) %in% unique(traindat[ , fact])
if (!all(levs)) {
test <- test[-which(!testdat[ , fact] %in% unique(testdat[ , fact])[levs]), ]
print(paste0("Levels of ", i, " omitted from test data: ",
unique(testdat[ , fact])[!levs]))
}
}
train_x <- traindat[ , -which(names(traindat) == "Class")]
train_y <- as.numeric(traindat$Class) - 1
test_x <- testdat[ , -which(names(data) == "Class")]
test_y <- as.numeric(testdat$Class) - 1
## Fit regular GLMM tree
gt <- glmtree(Class ~ 1 | ., data = traindat, family = binomial)
pred_gt <- predict(gt, newdata = testdat, type = "response")
MSE[(k-1)*10+i, 1] <- mean((test_y - pred_gt)^2)
acc[(k-1)*10+i, 1] <- mean(test_y - pred_gt > .5)
tree_size[(k-1)*10+i, 1] <- (length(gt)-1)/2
library("foreign")
library("dbarts")
library("mlbench")
library("partykit")
library("glmertree")
## Generate train-test splits
fold_ids <- sample(rep(1:nfolds, times = ceiling(nrow(data)/nfolds)),
size = nrow(data), replace = FALSE)
## Select train and test data
traindat <- data[fold_ids != i, ]
testdat <- data[fold_ids == i, ]
## Check whether all factor levels in test are also in train, else move obs.
for (fact in c("street")) {
levs <- unique(testdat[ , fact]) %in% unique(traindat[ , fact])
if (!all(levs)) {
testdat <- testdat[-which(!testdat[ , fact] %in% unique(testdat[ , fact])[levs]), ]
print(paste0("Levels of ", i, " omitted from test data: ",
unique(testdat[ , fact])[!levs]))
}
}
data <- read.spss("Safety.sav", to.data.frame = TRUE)
sapply(data, function(x) table(is.na(x)))
data$unsafe <- as.numeric(data$unsafe)
data$street <- factor(data$street)
nfolds <- 10
nreps <- 5
ngensizes <- c(1, 5, 10)
palts <- c(0, 0.25, 0.5)
## Create objects for saving results
MSE <- data.frame(matrix(data = NA, nrow = nfolds*nreps,
ncol = 3 + length(ngensizes) + length(ngensizes)*length(palts)))
BaSmear_design <- expand.grid(ngensizes, palts)
colnames(BaSmear_design) <- c("ngen", "palt")
colnames(MSE) <- c("GLMM_tree", "Bart", "Ba",
paste0("BaBayes_N=", ngensizes),
paste0("BaSmear_N=", BaSmear_design[ , 1], "_palt=", BaSmear_design[ , 2]))
rownames(MSE) <- paste0("rep", sort(rep(1:nreps, times = nfolds)), "_fold", rep(1:nfolds, times = nreps))
#MSE <- MSE[ , -which(is.na(colnames(MSE)))]
tree_size <- MSE
set.seed(42)
## Generate train-test splits
fold_ids <- sample(rep(1:nfolds, times = ceiling(nrow(data)/nfolds)),
size = nrow(data), replace = FALSE)
## Select train and test data
traindat <- data[fold_ids != i, ]
testdat <- data[fold_ids == i, ]
## Check whether all factor levels in test are also in train, else move obs.
for (fact in c("street")) {
levs <- unique(testdat[ , fact]) %in% unique(traindat[ , fact])
if (!all(levs)) {
testdat <- testdat[-which(!testdat[ , fact] %in% unique(testdat[ , fact])[levs]), ]
print(paste0("Levels of ", i, " omitted from test data: ",
unique(testdat[ , fact])[!levs]))
}
}
## Fit regular GLMM tree
gt <- lmertree(unsafe ~ 1 | (1|street) | age + sex + economic + crowded,
data = traindat)
MSE[(k-1)*10+i, 1] <- mean((testdat$unsafe - pred_gt)^2)
tree_size[(k-1)*10+i, 1] <- (length(gt)-1)/2
## Fit Bayesian born-again approach
brt <- rbart_vi(unsafe ~ age + sex + economic + crowded, data = traindat,
group.by = traindat$street, group.by.test = testdat$street,
test = testdat, n.trees = 100,
combineChains = TRUE, verbose = FALSE)
## Fit Bayesian born-again approach
brt <- rbart_vi(unsafe ~ age + sex + economic + crowded, data = traindat,
group.by = traindat$street, group.by.test = testdat$street,
test = testdat, n.trees = 100,
combineChains = TRUE, verbose = FALSE)
MSE[(k-1)*10+i, 2] <- mean((testdat$unsafe - brt$yhat.test.mean)^2)
