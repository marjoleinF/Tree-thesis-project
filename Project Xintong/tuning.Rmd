---
title: "BART"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Load data

```{r}
data("BostonHousing")
BostonHousing$chas<-factor(BostonHousing$chas)
#index=sample(1:nrow(BostonHousing),floor(0.7*nrow(BostonHousing)))
n=1:nrow(BostonHousing)
index=sample(1:nrow(BostonHousing),0.7*floor(nrow(BostonHousing)))
train=BostonHousing[index,]
test=BostonHousing[-index]
```
BART (power and base)

```{r,eval=F,hide=T,echo=F}


library('dbarts')
#n_trees=c(50,100,200,300,400,500)
power=c(1,2,3)
base=c(0.7,0.9,1)

result=numeric(nrow(train_test))
rmse_train=numeric(5)
a=matrix(nrow=length(base),ncol=length(power))
set.seed(10)
for(k in 1:length(power)){
for (j in 1:length(base)) {
  for (i in 1:5) {
  
  train_test=train[seq(0,nrow(train),5),]
  train_train=train[-seq(0,nrow(train),5),]
  BART_train<-bart2(medv~.,data=train_train,test = train_test,power = power[k],base=base[j])
  #EV<-evtree(medv~.,data=train_train,alpha=alpha[j])
#result<-predict(EV,train_test)
  rmse_train[i]<-sqrt(mean((BART_train$yhat.test.mean-train_test$medv)^2))
#rmse_train[i]<-sqrt(mean((result-train_test$medv)^2))
  }
  a[j,k]=(mean(rmse_train))
}
  }
```
         [,1]     [,2]     [,3]
[1,] 3.051281 3.118191 3.082377
[2,] 3.072732 2.976301 3.220865
[3,] 3.034264 3.087594 3.102117
[4,] 2.969479 3.109318 3.074321
[5,] 2.925810 3.020387 2.988958

```{r,eval=F,hide=T,echo=F}
rmse<-matrix(nrow = length(base),ncol=length(power))
for(k in 1:length(power)){
for (j in 1:length(base)) {
BART<-bart2(medv~.,data=train,test = test,power = power[k],base=base[j])
  #EV<-evtree(medv~.,data=train_train,alpha=alpha[j])
#result<-predict(EV,train_test)
  rmse[j,k]<-sqrt(mean((BART$yhat.test.mean-test$medv)^2))
  }}
```
> rmse


> rmse
         [,1]     [,2]     [,3]
[1,] 3.494783 3.671592 3.670331
[2,] 3.607465 3.705308 3.651482
[3,] 3.466504 3.589084 3.574650
[4,] 3.489010 3.670495 3.652560
[5,] 3.369493 3.519774 3.550900
Larger base performs better.


Evtree (maxdepth and alpha)

```{r,eval=F,hide=T,echo=F}
#evtree
library('evtree')
maxdepth=c(7,8,9,10,11)
alpha=c(0.8,0.9,1,1.1,1.2)
result=numeric(nrow(train_test))
rmse_train=numeric(5)
b=matrix(nrow=length(alpha),ncol=length(maxdepth))
set.seed(10)
for(k in 1:length(maxdepth)){
for (j in 1:length(alpha)) {
  for (i in 1:5) {
  
  train_test=train[seq(0,nrow(train),5),]
  train_train=train[-seq(0,nrow(train),5),]
  #BART_train<-bart2(medv~.,data=train_train,test = train_test,power = power[k],base=base[j])
  EV<-evtree(medv~.,data=train_train,alpha=alpha[j],maxdepth=maxdepth[k])
result<-predict(EV,train_test)
  #rmse_train[i]<-sqrt(mean((BART_train$yhat.test.mean-train_test$medv)^2))
rmse_train[i]<-sqrt(mean((result-train_test$medv)^2))
  }
  b[j,k]=(mean(rmse_train))
}
  }
```
         [,1]     [,2]     [,3]     [,4]     [,5]
[1,] 4.094553 4.128094 3.573831 3.704097 4.006669
[2,] 3.696499 3.692618 3.730924 3.692778 3.726685
[3,] 4.065005 3.739498 3.239977 3.766429 3.954863
[4,] 4.271980 3.847111 3.938041 4.427095 4.247045
[5,] 4.025130 4.104339 3.890417 4.017046 3.863185

```{r,eval=F,hide=T,echo=F}
set.seed(10)
result_ev<-nrow(test)
rmse_ev=matrix(nrow=length(alpha),ncol=length(maxdepth))
set.seed(10)
for(k in 1:length(maxdepth)){
for (j in 1:length(alpha)) {
  #BART_train<-bart2(medv~.,data=train_train,test = train_test,power = power[k],base=base[j])
  EV<-evtree(medv~.,data=train,alpha=alpha[j],maxdepth=maxdepth[k])
result_ev<-predict(EV,test)
  #rmse_train[i]<-sqrt(mean((BART_train$yhat.test.mean-train_test$medv)^2))
rmse_ev[j,k]<-sqrt(mean((result_ev-test$medv)^2))

}}

```

Default value of maxdepth(9) and alpha(1) performs best.




































